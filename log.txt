[2025-01-07 18:35:51,109] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-07 18:35:53,032] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-01-07 18:35:53,032] [INFO] [runner.py:555:main] cmd = /home/myid/mj71006/anaconda3/envs/videollava/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None videollava/train/train_mem.py --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 --deepspeed ./scripts/zero3.json --model_name_or_path lmsys/vicuna-7b-v1.5 --version v1 --data_path llava_all_image_video/ft_json/videochatgpt_tune_.json --image_folder llava_all_image_video --image_tower LanguageBind/LanguageBind_Image --video_folder llava_all_image_video/medication --video_tower LanguageBind/LanguageBind_Video_merge --mm_projector_type mlp2x_gelu --pretrain_mm_mlp_adapter ./checkpoints/videollava-7b-pretrain/mm_projector.bin --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir ./checkpoints/videollava-7b-lora --num_train_epochs 100 --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --gradient_accumulation_steps 4 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-4 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --tokenizer_model_max_length 3072 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to tensorboard --cache_dir ./cache_dir
[2025-01-07 18:35:54,201] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-07 18:35:56,009] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2025-01-07 18:35:56,009] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0
[2025-01-07 18:35:56,009] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2025-01-07 18:35:56,009] [INFO] [launch.py:163:main] dist_world_size=8
[2025-01-07 18:35:56,009] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2025-01-07 18:35:59,047] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-07 18:35:59,094] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-07 18:35:59,096] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-07 18:35:59,103] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-07 18:35:59,112] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-07 18:35:59,141] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-07 18:35:59,156] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-07 18:35:59,159] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.
  warnings.warn(
[2025-01-07 18:35:59,979] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-01-07 18:35:59,979] [INFO] [comm.py:594:init_distributed] cdb=None
[2025-01-07 18:35:59,979] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-01-07 18:36:00,021] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-01-07 18:36:00,021] [INFO] [comm.py:594:init_distributed] cdb=None
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.
  warnings.warn(
[2025-01-07 18:36:00,070] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-01-07 18:36:00,070] [INFO] [comm.py:594:init_distributed] cdb=None
[2025-01-07 18:36:00,070] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-01-07 18:36:00,071] [INFO] [comm.py:594:init_distributed] cdb=None
[2025-01-07 18:36:00,131] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-01-07 18:36:00,131] [INFO] [comm.py:594:init_distributed] cdb=None
[2025-01-07 18:36:00,140] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-01-07 18:36:00,141] [INFO] [comm.py:594:init_distributed] cdb=None
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.
  warnings.warn(
[2025-01-07 18:36:00,208] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-01-07 18:36:00,208] [INFO] [comm.py:594:init_distributed] cdb=None
[2025-01-07 18:36:00,262] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-01-07 18:36:00,262] [INFO] [comm.py:594:init_distributed] cdb=None
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using a model of type llama to instantiate a model of type llava. This is not supported for all configurations of models and can yield errors.
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using a model of type llama to instantiate a model of type llava. This is not supported for all configurations of models and can yield errors.
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using a model of type llama to instantiate a model of type llava. This is not supported for all configurations of models and can yield errors.
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using a model of type llama to instantiate a model of type llava. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava. This is not supported for all configurations of models and can yield errors.
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using a model of type llama to instantiate a model of type llava. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava. This is not supported for all configurations of models and can yield errors.
/home/myid/mj71006/anaconda3/envs/videollava/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using a model of type llama to instantiate a model of type llava. This is not supported for all configurations of models and can yield errors.
[2025-01-07 18:36:04,460] [INFO] [partition_parameters.py:453:__exit__] finished initializing model with 6.74B parameters
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.68s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.69s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.71s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.72s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.74s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.79s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.79s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.21s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.21s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.22s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.22s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.23s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.23s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.23s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.10s/it]
Adding LoRA adapters...
[2025-01-07 18:37:47,702] [WARNING] [partition_parameters.py:836:_post_init_method] param `class_embedding` in CLIPVisionEmbeddings not on GPU so was not broadcasted from rank 0
[2025-01-07 18:37:48,913] [WARNING] [partition_parameters.py:836:_post_init_method] param `logit_scale` in LanguageBindImage not on GPU so was not broadcasted from rank 0
[2025-01-07 18:37:48,936] [INFO] [partition_parameters.py:453:__exit__] finished initializing model with 7.17B parameters
[2025-01-07 18:37:50,506] [WARNING] [partition_parameters.py:836:_post_init_method] param `class_embedding` in CLIPVisionEmbeddings not on GPU so was not broadcasted from rank 0
[2025-01-07 18:37:51,572] [WARNING] [partition_parameters.py:836:_post_init_method] param `logit_scale` in LanguageBindVideo not on GPU so was not broadcasted from rank 0
[2025-01-07 18:37:51,601] [INFO] [partition_parameters.py:453:__exit__] finished initializing model with 7.69B parameters
Formatting inputs...Skip in lazy mode
Parameter Offload: Total persistent parameters: 1267712 in 725 params
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:09<16:18,  9.88s/it]                                               {'loss': 0.6458, 'learning_rate': 6.666666666666667e-05, 'epoch': 1.0}
  1%|          | 1/100 [00:09<16:18,  9.88s/it]  2%|▏         | 2/100 [00:16<13:10,  8.07s/it]                                               {'loss': 0.6496, 'learning_rate': 0.00013333333333333334, 'epoch': 2.0}
  2%|▏         | 2/100 [00:16<13:10,  8.07s/it]  3%|▎         | 3/100 [00:22<11:20,  7.02s/it]                                               {'loss': 0.6459, 'learning_rate': 0.0002, 'epoch': 3.0}
  3%|▎         | 3/100 [00:22<11:20,  7.02s/it]  4%|▍         | 4/100 [00:28<10:30,  6.57s/it]                                               {'loss': 0.6468, 'learning_rate': 0.00019994755690455152, 'epoch': 4.0}
  4%|▍         | 4/100 [00:28<10:30,  6.57s/it]  5%|▌         | 5/100 [00:34<09:56,  6.28s/it]                                               {'loss': 0.3749, 'learning_rate': 0.00019979028262377118, 'epoch': 5.0}
  5%|▌         | 5/100 [00:34<09:56,  6.28s/it]  6%|▌         | 6/100 [00:39<09:36,  6.13s/it]                                               {'loss': 0.3726, 'learning_rate': 0.0001995283421166614, 'epoch': 6.0}
  6%|▌         | 6/100 [00:39<09:36,  6.13s/it]  7%|▋         | 7/100 [00:45<09:18,  6.01s/it]                                               {'loss': 0.3756, 'learning_rate': 0.00019916201012264254, 'epoch': 7.0}
  7%|▋         | 7/100 [00:45<09:18,  6.01s/it]  8%|▊         | 8/100 [00:51<09:12,  6.00s/it]                                               {'loss': 0.3718, 'learning_rate': 0.00019869167087338907, 'epoch': 8.0}
  8%|▊         | 8/100 [00:51<09:12,  6.00s/it]  9%|▉         | 9/100 [00:57<09:01,  5.95s/it]                                               {'loss': 0.1666, 'learning_rate': 0.0001981178176898239, 'epoch': 9.0}
  9%|▉         | 9/100 [00:57<09:01,  5.95s/it] 10%|█         | 10/100 [01:03<08:51,  5.91s/it]                                                {'loss': 0.1714, 'learning_rate': 0.00019744105246469263, 'epoch': 10.0}
 10%|█         | 10/100 [01:03<08:51,  5.91s/it] 11%|█         | 11/100 [01:09<08:43,  5.89s/it]                                                {'loss': 0.1669, 'learning_rate': 0.00019666208503126112, 'epoch': 11.0}
 11%|█         | 11/100 [01:09<08:43,  5.89s/it] 12%|█▏        | 12/100 [01:15<08:40,  5.92s/it]                                                {'loss': 0.1663, 'learning_rate': 0.00019578173241879872, 'epoch': 12.0}
 12%|█▏        | 12/100 [01:15<08:40,  5.92s/it] 13%|█▎        | 13/100 [01:21<08:34,  5.91s/it]                                                {'loss': 0.0884, 'learning_rate': 0.00019480091799562704, 'epoch': 13.0}
 13%|█▎        | 13/100 [01:21<08:34,  5.91s/it] 14%|█▍        | 14/100 [01:26<08:27,  5.90s/it]                                                {'loss': 0.0882, 'learning_rate': 0.00019372067050063438, 'epoch': 14.0}
 14%|█▍        | 14/100 [01:26<08:27,  5.90s/it] 15%|█▌        | 15/100 [01:32<08:19,  5.88s/it]                                                {'loss': 0.092, 'learning_rate': 0.00019254212296427044, 'epoch': 15.0}
 15%|█▌        | 15/100 [01:32<08:19,  5.88s/it] 16%|█▌        | 16/100 [01:38<08:17,  5.92s/it]                                                {'loss': 0.0919, 'learning_rate': 0.00019126651152015403, 'epoch': 16.0}
 16%|█▌        | 16/100 [01:38<08:17,  5.92s/it] 17%|█▋        | 17/100 [01:44<08:09,  5.90s/it]                                                {'loss': 0.0567, 'learning_rate': 0.00018989517410853955, 'epoch': 17.0}
 17%|█▋        | 17/100 [01:44<08:09,  5.90s/it] 18%|█▊        | 18/100 [01:50<08:02,  5.88s/it]                                                {'loss': 0.0567, 'learning_rate': 0.00018842954907300236, 'epoch': 18.0}
 18%|█▊        | 18/100 [01:50<08:02,  5.88s/it] 19%|█▉        | 19/100 [01:56<07:55,  5.87s/it]                                                {'loss': 0.0571, 'learning_rate': 0.00018687117365181512, 'epoch': 19.0}
 19%|█▉        | 19/100 [01:56<07:55,  5.87s/it] 20%|██        | 20/100 [02:02<07:52,  5.90s/it]                                                {'loss': 0.0571, 'learning_rate': 0.00018522168236559695, 'epoch': 20.0}
 20%|██        | 20/100 [02:02<07:52,  5.90s/it] 21%|██        | 21/100 [02:08<07:49,  5.94s/it]                                                {'loss': 0.0297, 'learning_rate': 0.00018348280530292713, 'epoch': 21.0}
 21%|██        | 21/100 [02:08<07:49,  5.94s/it] 22%|██▏       | 22/100 [02:14<07:46,  5.99s/it]                                                {'loss': 0.0283, 'learning_rate': 0.0001816563663057211, 'epoch': 22.0}
 22%|██▏       | 22/100 [02:14<07:46,  5.99s/it] 23%|██▎       | 23/100 [02:20<07:41,  6.00s/it]                                                {'loss': 0.0298, 'learning_rate': 0.00017974428105627208, 'epoch': 23.0}
 23%|██▎       | 23/100 [02:20<07:41,  6.00s/it] 24%|██▍       | 24/100 [02:26<07:39,  6.05s/it]                                                {'loss': 0.0282, 'learning_rate': 0.00017774855506796496, 'epoch': 24.0}
 24%|██▍       | 24/100 [02:26<07:39,  6.05s/it] 25%|██▌       | 25/100 [02:32<07:35,  6.08s/it]                                                {'loss': 0.0241, 'learning_rate': 0.00017567128158176953, 'epoch': 25.0}
 25%|██▌       | 25/100 [02:32<07:35,  6.08s/it] 26%|██▌       | 26/100 [02:38<07:29,  6.07s/it]                                                {'loss': 0.0243, 'learning_rate': 0.00017351463937072004, 'epoch': 26.0}
 26%|██▌       | 26/100 [02:38<07:29,  6.07s/it] 27%|██▋       | 27/100 [02:44<07:21,  6.05s/it]                                                {'loss': 0.0245, 'learning_rate': 0.00017128089045468294, 'epoch': 27.0}
 27%|██▋       | 27/100 [02:44<07:21,  6.05s/it] 28%|██▊       | 28/100 [02:51<07:18,  6.10s/it]                                                {'loss': 0.0243, 'learning_rate': 0.00016897237772781044, 'epoch': 28.0}
 28%|██▊       | 28/100 [02:51<07:18,  6.10s/it] 29%|██▉       | 29/100 [02:57<07:12,  6.10s/it]                                                {'loss': 0.0124, 'learning_rate': 0.00016659152250116812, 'epoch': 29.0}
 29%|██▉       | 29/100 [02:57<07:12,  6.10s/it] 30%|███       | 30/100 [03:03<07:06,  6.10s/it]                                                {'loss': 0.0116, 'learning_rate': 0.000164140821963114, 'epoch': 30.0}
 30%|███       | 30/100 [03:03<07:06,  6.10s/it] 31%|███       | 31/100 [03:09<07:00,  6.09s/it]                                                {'loss': 0.0115, 'learning_rate': 0.00016162284656009274, 'epoch': 31.0}
 31%|███       | 31/100 [03:09<07:00,  6.09s/it] 32%|███▏      | 32/100 [03:15<06:56,  6.12s/it]                                                {'loss': 0.0111, 'learning_rate': 0.00015904023730059228, 'epoch': 32.0}
 32%|███▏      | 32/100 [03:15<06:56,  6.12s/it] 33%|███▎      | 33/100 [03:21<06:49,  6.12s/it]                                                {'loss': 0.0096, 'learning_rate': 0.00015639570298509064, 'epoch': 33.0}
 33%|███▎      | 33/100 [03:21<06:49,  6.12s/it] 34%|███▍      | 34/100 [03:27<06:41,  6.09s/it]                                                {'loss': 0.0101, 'learning_rate': 0.0001536920173648984, 'epoch': 34.0}
 34%|███▍      | 34/100 [03:27<06:41,  6.09s/it] 35%|███▌      | 35/100 [03:33<06:35,  6.09s/it]                                                {'loss': 0.0098, 'learning_rate': 0.00015093201623287631, 'epoch': 35.0}
 35%|███▌      | 35/100 [03:33<06:35,  6.09s/it] 36%|███▌      | 36/100 [03:39<06:29,  6.09s/it]                                                {'loss': 0.0103, 'learning_rate': 0.00014811859444908052, 'epoch': 36.0}
 36%|███▌      | 36/100 [03:39<06:29,  6.09s/it] 37%|███▋      | 37/100 [03:45<06:23,  6.09s/it]                                                {'loss': 0.0055, 'learning_rate': 0.00014525470290445392, 'epoch': 37.0}
 37%|███▋      | 37/100 [03:45<06:23,  6.09s/it] 38%|███▊      | 38/100 [03:51<06:17,  6.09s/it]                                                {'loss': 0.0054, 'learning_rate': 0.00014234334542574906, 'epoch': 38.0}
 38%|███▊      | 38/100 [03:51<06:17,  6.09s/it] 39%|███▉      | 39/100 [03:58<06:11,  6.10s/it]                                                {'loss': 0.0054, 'learning_rate': 0.00013938757562492873, 'epoch': 39.0}
 39%|███▉      | 39/100 [03:58<06:11,  6.10s/it] 40%|████      | 40/100 [04:04<06:07,  6.12s/it]                                                {'loss': 0.006, 'learning_rate': 0.00013639049369634876, 'epoch': 40.0}
 40%|████      | 40/100 [04:04<06:07,  6.12s/it] 41%|████      | 41/100 [04:10<05:59,  6.10s/it]                                                {'loss': 0.0034, 'learning_rate': 0.00013335524316508208, 'epoch': 41.0}
 41%|████      | 41/100 [04:10<05:59,  6.10s/it] 42%|████▏     | 42/100 [04:16<05:53,  6.09s/it]                                                {'loss': 0.0032, 'learning_rate': 0.00013028500758979506, 'epoch': 42.0}
 42%|████▏     | 42/100 [04:16<05:53,  6.09s/it] 43%|████▎     | 43/100 [04:22<05:46,  6.09s/it]                                                {'loss': 0.0034, 'learning_rate': 0.0001271830072236343, 'epoch': 43.0}
 43%|████▎     | 43/100 [04:22<05:46,  6.09s/it] 44%|████▍     | 44/100 [04:28<05:41,  6.10s/it]                                                {'loss': 0.0034, 'learning_rate': 0.00012405249563662537, 'epoch': 44.0}
 44%|████▍     | 44/100 [04:28<05:41,  6.10s/it] 45%|████▌     | 45/100 [04:34<05:35,  6.10s/it]                                                {'loss': 0.0016, 'learning_rate': 0.00012089675630312754, 'epoch': 45.0}
 45%|████▌     | 45/100 [04:34<05:35,  6.10s/it] 46%|████▌     | 46/100 [04:40<05:28,  6.08s/it]                                                {'loss': 0.0015, 'learning_rate': 0.0001177190991579223, 'epoch': 46.0}
 46%|████▌     | 46/100 [04:40<05:28,  6.08s/it] 47%|████▋     | 47/100 [04:46<05:22,  6.08s/it]                                                {'loss': 0.0015, 'learning_rate': 0.00011452285712454904, 'epoch': 47.0}
 47%|████▋     | 47/100 [04:46<05:22,  6.08s/it] 48%|████▊     | 48/100 [04:52<05:18,  6.12s/it]                                                {'loss': 0.0015, 'learning_rate': 0.00011131138261952845, 'epoch': 48.0}
 48%|████▊     | 48/100 [04:52<05:18,  6.12s/it] 49%|████▉     | 49/100 [04:59<05:10,  6.09s/it]                                                {'loss': 0.0007, 'learning_rate': 0.00010808804403614043, 'epoch': 49.0}
 49%|████▉     | 49/100 [04:59<05:10,  6.09s/it] 50%|█████     | 50/100 [05:05<05:03,  6.06s/it]                                                {'loss': 0.0007, 'learning_rate': 0.00010485622221144484, 'epoch': 50.0}
 50%|█████     | 50/100 [05:05<05:03,  6.06s/it] 51%|█████     | 51/100 [05:11<04:56,  6.06s/it]                                                {'loss': 0.0007, 'learning_rate': 0.00010161930688025017, 'epoch': 51.0}
 51%|█████     | 51/100 [05:11<04:56,  6.06s/it] 52%|█████▏    | 52/100 [05:17<04:52,  6.09s/it]                                                {'loss': 0.0007, 'learning_rate': 9.838069311974986e-05, 'epoch': 52.0}
 52%|█████▏    | 52/100 [05:17<04:52,  6.09s/it] 53%|█████▎    | 53/100 [05:23<04:46,  6.10s/it]                                                {'loss': 0.0006, 'learning_rate': 9.514377778855521e-05, 'epoch': 53.0}
 53%|█████▎    | 53/100 [05:23<04:46,  6.10s/it] 54%|█████▍    | 54/100 [05:29<04:39,  6.08s/it]                                                {'loss': 0.0006, 'learning_rate': 9.19119559638596e-05, 'epoch': 54.0}
 54%|█████▍    | 54/100 [05:29<04:39,  6.08s/it] 55%|█████▌    | 55/100 [05:35<04:32,  6.06s/it]                                                {'loss': 0.0006, 'learning_rate': 8.868861738047158e-05, 'epoch': 55.0}
 55%|█████▌    | 55/100 [05:35<04:32,  6.06s/it] 56%|█████▌    | 56/100 [05:41<04:28,  6.10s/it]                                                {'loss': 0.0005, 'learning_rate': 8.5477142875451e-05, 'epoch': 56.0}
 56%|█████▌    | 56/100 [05:41<04:28,  6.10s/it] 57%|█████▋    | 57/100 [05:47<04:21,  6.08s/it]                                                {'loss': 0.0005, 'learning_rate': 8.228090084207774e-05, 'epoch': 57.0}
 57%|█████▋    | 57/100 [05:47<04:21,  6.08s/it] 58%|█████▊    | 58/100 [05:53<04:14,  6.07s/it]                                                {'loss': 0.0005, 'learning_rate': 7.91032436968725e-05, 'epoch': 58.0}
 58%|█████▊    | 58/100 [05:53<04:14,  6.07s/it] 59%|█████▉    | 59/100 [05:59<04:08,  6.06s/it]                                                {'loss': 0.0005, 'learning_rate': 7.594750436337467e-05, 'epoch': 59.0}
 59%|█████▉    | 59/100 [05:59<04:08,  6.06s/it] 60%|██████    | 60/100 [06:05<04:04,  6.12s/it]                                                {'loss': 0.0005, 'learning_rate': 7.281699277636572e-05, 'epoch': 60.0}
 60%|██████    | 60/100 [06:05<04:04,  6.12s/it] 61%|██████    | 61/100 [06:12<03:57,  6.10s/it]                                                {'loss': 0.0003, 'learning_rate': 6.971499241020495e-05, 'epoch': 61.0}
 61%|██████    | 61/100 [06:12<03:57,  6.10s/it] 62%|██████▏   | 62/100 [06:18<03:51,  6.09s/it]                                                {'loss': 0.0003, 'learning_rate': 6.664475683491796e-05, 'epoch': 62.0}
 62%|██████▏   | 62/100 [06:18<03:51,  6.09s/it] 63%|██████▎   | 63/100 [06:24<03:45,  6.09s/it]                                                {'loss': 0.0003, 'learning_rate': 6.360950630365126e-05, 'epoch': 63.0}
 63%|██████▎   | 63/100 [06:24<03:45,  6.09s/it] 64%|██████▍   | 64/100 [06:30<03:40,  6.12s/it]                                                {'loss': 0.0003, 'learning_rate': 6.061242437507131e-05, 'epoch': 64.0}
 64%|██████▍   | 64/100 [06:30<03:40,  6.12s/it] 65%|██████▌   | 65/100 [06:36<03:33,  6.10s/it]                                                {'loss': 0.0002, 'learning_rate': 5.765665457425102e-05, 'epoch': 65.0}
 65%|██████▌   | 65/100 [06:36<03:33,  6.10s/it] 66%|██████▌   | 66/100 [06:42<03:26,  6.08s/it]                                                {'loss': 0.0002, 'learning_rate': 5.474529709554612e-05, 'epoch': 66.0}
 66%|██████▌   | 66/100 [06:42<03:26,  6.08s/it] 67%|██████▋   | 67/100 [06:48<03:20,  6.08s/it]                                                {'loss': 0.0002, 'learning_rate': 5.1881405550919493e-05, 'epoch': 67.0}
 67%|██████▋   | 67/100 [06:48<03:20,  6.08s/it] 68%|██████▊   | 68/100 [06:54<03:15,  6.11s/it]                                                {'loss': 0.0002, 'learning_rate': 4.9067983767123736e-05, 'epoch': 68.0}
 68%|██████▊   | 68/100 [06:54<03:15,  6.11s/it] 69%|██████▉   | 69/100 [07:00<03:08,  6.09s/it]                                                {'loss': 0.0002, 'learning_rate': 4.630798263510162e-05, 'epoch': 69.0}
 69%|██████▉   | 69/100 [07:00<03:08,  6.09s/it] 70%|███████   | 70/100 [07:06<03:02,  6.10s/it]                                                {'loss': 0.0002, 'learning_rate': 4.360429701490934e-05, 'epoch': 70.0}
 70%|███████   | 70/100 [07:06<03:02,  6.10s/it] 71%|███████   | 71/100 [07:13<02:58,  6.14s/it]                                                {'loss': 0.0002, 'learning_rate': 4.0959762699407766e-05, 'epoch': 71.0}
 71%|███████   | 71/100 [07:13<02:58,  6.14s/it] 72%|███████▏  | 72/100 [07:19<02:52,  6.16s/it]                                                {'loss': 0.0002, 'learning_rate': 3.8377153439907266e-05, 'epoch': 72.0}
 72%|███████▏  | 72/100 [07:19<02:52,  6.16s/it] 73%|███████▎  | 73/100 [07:25<02:45,  6.14s/it]                                                {'loss': 0.0001, 'learning_rate': 3.585917803688603e-05, 'epoch': 73.0}
 73%|███████▎  | 73/100 [07:25<02:45,  6.14s/it] 74%|███████▍  | 74/100 [07:31<02:38,  6.10s/it]                                                {'loss': 0.0001, 'learning_rate': 3.340847749883191e-05, 'epoch': 74.0}
 74%|███████▍  | 74/100 [07:31<02:38,  6.10s/it] 75%|███████▌  | 75/100 [07:37<02:32,  6.11s/it]                                                {'loss': 0.0001, 'learning_rate': 3.102762227218957e-05, 'epoch': 75.0}
 75%|███████▌  | 75/100 [07:37<02:32,  6.11s/it] 76%|███████▌  | 76/100 [07:43<02:27,  6.13s/it]                                                {'loss': 0.0001, 'learning_rate': 2.8719109545317103e-05, 'epoch': 76.0}
 76%|███████▌  | 76/100 [07:43<02:27,  6.13s/it] 77%|███████▋  | 77/100 [07:49<02:20,  6.11s/it]                                                {'loss': 0.0001, 'learning_rate': 2.6485360629279987e-05, 'epoch': 77.0}
 77%|███████▋  | 77/100 [07:49<02:20,  6.11s/it] 78%|███████▊  | 78/100 [07:55<02:14,  6.10s/it]                                                {'loss': 0.0001, 'learning_rate': 2.432871841823047e-05, 'epoch': 78.0}
 78%|███████▊  | 78/100 [07:55<02:14,  6.10s/it] 79%|███████▉  | 79/100 [08:01<02:07,  6.09s/it]                                                {'loss': 0.0001, 'learning_rate': 2.2251444932035094e-05, 'epoch': 79.0}
 79%|███████▉  | 79/100 [08:01<02:07,  6.09s/it] 80%|████████  | 80/100 [08:08<02:02,  6.13s/it]                                                {'loss': 0.0001, 'learning_rate': 2.025571894372794e-05, 'epoch': 80.0}
 80%|████████  | 80/100 [08:08<02:02,  6.13s/it] 81%|████████  | 81/100 [08:14<01:56,  6.12s/it]                                                {'loss': 0.0001, 'learning_rate': 1.8343633694278895e-05, 'epoch': 81.0}
 81%|████████  | 81/100 [08:14<01:56,  6.12s/it] 82%|████████▏ | 82/100 [08:20<01:49,  6.11s/it]                                                {'loss': 0.0001, 'learning_rate': 1.65171946970729e-05, 'epoch': 82.0}
 82%|████████▏ | 82/100 [08:20<01:49,  6.11s/it] 83%|████████▎ | 83/100 [08:26<01:43,  6.10s/it]                                                {'loss': 0.0001, 'learning_rate': 1.4778317634403083e-05, 'epoch': 83.0}
 83%|████████▎ | 83/100 [08:26<01:43,  6.10s/it] 84%|████████▍ | 84/100 [08:32<01:38,  6.13s/it]                                                {'loss': 0.0001, 'learning_rate': 1.3128826348184887e-05, 'epoch': 84.0}
 84%|████████▍ | 84/100 [08:32<01:38,  6.13s/it] 85%|████████▌ | 85/100 [08:38<01:31,  6.12s/it]                                                {'loss': 0.0001, 'learning_rate': 1.1570450926997655e-05, 'epoch': 85.0}
 85%|████████▌ | 85/100 [08:38<01:31,  6.12s/it] 86%|████████▌ | 86/100 [08:44<01:25,  6.09s/it]                                                {'loss': 0.0001, 'learning_rate': 1.010482589146048e-05, 'epoch': 86.0}
 86%|████████▌ | 86/100 [08:44<01:25,  6.09s/it] 87%|████████▋ | 87/100 [08:50<01:18,  6.07s/it]                                                {'loss': 0.0001, 'learning_rate': 8.733488479845997e-06, 'epoch': 87.0}
 87%|████████▋ | 87/100 [08:50<01:18,  6.07s/it] 88%|████████▊ | 88/100 [08:56<01:13,  6.11s/it]                                                {'loss': 0.0001, 'learning_rate': 7.457877035729588e-06, 'epoch': 88.0}
 88%|████████▊ | 88/100 [08:56<01:13,  6.11s/it] 89%|████████▉ | 89/100 [09:02<01:07,  6.09s/it]                                                {'loss': 0.0001, 'learning_rate': 6.2793294993656494e-06, 'epoch': 89.0}
 89%|████████▉ | 89/100 [09:02<01:07,  6.09s/it] 90%|█████████ | 90/100 [09:09<01:00,  6.07s/it]                                                {'loss': 0.0001, 'learning_rate': 5.199082004372957e-06, 'epoch': 90.0}
 90%|█████████ | 90/100 [09:09<01:00,  6.07s/it] 91%|█████████ | 91/100 [09:15<00:54,  6.06s/it]                                                {'loss': 0.0001, 'learning_rate': 4.2182675812012965e-06, 'epoch': 91.0}
 91%|█████████ | 91/100 [09:15<00:54,  6.06s/it] 92%|█████████▏| 92/100 [09:21<00:48,  6.09s/it]                                                {'loss': 0.0001, 'learning_rate': 3.3379149687388867e-06, 'epoch': 92.0}
 92%|█████████▏| 92/100 [09:21<00:48,  6.09s/it] 93%|█████████▎| 93/100 [09:27<00:42,  6.08s/it]                                                {'loss': 0.0001, 'learning_rate': 2.5589475353073988e-06, 'epoch': 93.0}
 93%|█████████▎| 93/100 [09:27<00:42,  6.08s/it] 94%|█████████▍| 94/100 [09:33<00:36,  6.08s/it]                                                {'loss': 0.0001, 'learning_rate': 1.882182310176095e-06, 'epoch': 94.0}
 94%|█████████▍| 94/100 [09:33<00:36,  6.08s/it] 95%|█████████▌| 95/100 [09:39<00:30,  6.06s/it]                                                {'loss': 0.0001, 'learning_rate': 1.30832912661093e-06, 'epoch': 95.0}
 95%|█████████▌| 95/100 [09:39<00:30,  6.06s/it] 96%|█████████▌| 96/100 [09:45<00:24,  6.11s/it]                                                {'loss': 0.0001, 'learning_rate': 8.379898773574924e-07, 'epoch': 96.0}
 96%|█████████▌| 96/100 [09:45<00:24,  6.11s/it] 97%|█████████▋| 97/100 [09:51<00:18,  6.09s/it]                                                {'loss': 0.0001, 'learning_rate': 4.7165788333860536e-07, 'epoch': 97.0}
 97%|█████████▋| 97/100 [09:51<00:18,  6.09s/it] 98%|█████████▊| 98/100 [09:57<00:12,  6.09s/it]                                                {'loss': 0.0001, 'learning_rate': 2.0971737622883515e-07, 'epoch': 98.0}
 98%|█████████▊| 98/100 [09:57<00:12,  6.09s/it] 99%|█████████▉| 99/100 [10:03<00:06,  6.07s/it]                                                {'loss': 0.0001, 'learning_rate': 5.2443095448506674e-08, 'epoch': 99.0}
 99%|█████████▉| 99/100 [10:03<00:06,  6.07s/it]100%|██████████| 100/100 [10:09<00:00,  6.10s/it]                                                 {'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 100.0}
100%|██████████| 100/100 [10:09<00:00,  6.10s/it]                                                 {'train_runtime': 609.9011, 'train_samples_per_second': 1.64, 'train_steps_per_second': 0.164, 'train_loss': 0.05696336132219585, 'epoch': 100.0}
100%|██████████| 100/100 [10:09<00:00,  6.10s/it]100%|██████████| 100/100 [10:09<00:00,  6.10s/it]
[2025-01-07 18:48:28,865] [INFO] [launch.py:347:main] Process 3247221 exits successfully.
[2025-01-07 18:48:28,866] [INFO] [launch.py:347:main] Process 3247224 exits successfully.
[2025-01-07 18:48:28,866] [INFO] [launch.py:347:main] Process 3247223 exits successfully.
[2025-01-07 18:48:28,866] [INFO] [launch.py:347:main] Process 3247220 exits successfully.
[2025-01-07 18:48:28,866] [INFO] [launch.py:347:main] Process 3247222 exits successfully.
[2025-01-07 18:48:28,866] [INFO] [launch.py:347:main] Process 3247218 exits successfully.
[2025-01-07 18:48:29,868] [INFO] [launch.py:347:main] Process 3247217 exits successfully.
[2025-01-07 18:48:29,868] [INFO] [launch.py:347:main] Process 3247219 exits successfully.
